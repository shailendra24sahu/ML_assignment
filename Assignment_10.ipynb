{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470c682d",
   "metadata": {},
   "source": [
    "Q1. Define the Bayesian interpretation of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc20eb",
   "metadata": {},
   "source": [
    "The Bayesian interpretation of probability is a philosophical and mathematical framework that provides a subjective view of probability as a measure of uncertainty. It is named after the Reverend Thomas Bayes, an 18th-century English statistician and theologian.\n",
    "\n",
    "In the Bayesian interpretation, probability is seen as a degree of belief or confidence in the truth of a proposition, based on available evidence or prior knowledge. It allows for the updating of beliefs in light of new evidence using Bayes' theorem.\n",
    "\n",
    "The Bayesian approach starts with an initial belief or prior probability, which represents the individual's subjective opinion about the likelihood of an event or hypothesis. This prior belief can be based on personal experience, expert opinions, or any other relevant information. As new evidence becomes available, the prior belief is updated to a posterior probability using Bayes' theorem.\n",
    "\n",
    "Bayes' theorem states that the posterior probability of a hypothesis is proportional to the product of the prior probability and the likelihood of the evidence given the hypothesis. Mathematically, it can be expressed as:\n",
    "\n",
    "````\n",
    "P(H | E) = (P(E | H) * P(H)) / P(E)\n",
    "\n",
    "where:\n",
    "P(H | E) is the posterior probability of the hypothesis H given the evidence E,\n",
    "P(E | H) is the likelihood of the evidence E given the hypothesis H,\n",
    "P(H) is the prior probability of the hypothesis H, and\n",
    "P(E) is the probability of the evidence E.\n",
    "````\n",
    "\n",
    "The Bayesian interpretation allows for the iterative process of updating probabilities as new evidence is acquired. This makes it particularly useful in decision-making, data analysis, and scientific inference, as it provides a coherent framework for incorporating prior knowledge and updating beliefs based on observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a71fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497fcfea",
   "metadata": {},
   "source": [
    "Q2. Define probability of a union of two events with equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0de47",
   "metadata": {},
   "source": [
    "The probability of the union of two events A and B, denoted as P(A ∪ B), is the probability that at least one of the events A or B occurs.\n",
    "\n",
    "The equation for the probability of the union of two events is given by:\n",
    "\n",
    "````\n",
    "P(A ∪ B) = P(A) + P(B) - P(A ∩ B)\n",
    "\n",
    "where:\n",
    "P(A) represents the probability of event A,\n",
    "P(B) represents the probability of event B, and\n",
    "P(A ∩ B) represents the probability of the intersection of events A and B, i.e., the probability that both A and B occur simultaneously.\n",
    "````\n",
    "\n",
    "The formula accounts for the fact that when calculating the probability of the union of two events, the intersection of the events (the event where both A and B occur) is counted twice if not subtracted.\n",
    "\n",
    "By subtracting the probability of the intersection, we ensure that the overlapping region is not counted twice, resulting in an accurate calculation of the probability of the union of A and B.\n",
    "\n",
    "Note that this equation holds for any two events, whether they are mutually exclusive (cannot occur simultaneously) or not. In the case of mutually exclusive events, the probability of their intersection, P(A ∩ B), is zero, simplifying the equation to:\n",
    "\n",
    "P(A ∪ B) = P(A) + P(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1766ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bf038e4",
   "metadata": {},
   "source": [
    "Q3. What is joint probability? What is its formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1c50e7",
   "metadata": {},
   "source": [
    "Joint probability refers to the probability of two or more events occurring simultaneously. It quantifies the likelihood of the intersection of multiple events.\n",
    "\n",
    "The joint probability of two events A and B is denoted as P(A ∩ B) or P(A, B). It represents the probability of both events A and B occurring together.\n",
    "\n",
    "The formula for the joint probability of two events is as follows:\n",
    "\n",
    "````\n",
    "P(A ∩ B) = P(A) * P(B|A)\n",
    "\n",
    "where:\n",
    "P(A) represents the probability of event A,\n",
    "P(B|A) represents the conditional probability of event B given that event A has occurred.\n",
    "````\n",
    "\n",
    "The formula states that the joint probability of events A and B is equal to the probability of event A multiplied by the conditional probability of event B given event A.\n",
    "\n",
    "This formula reflects the idea that the joint probability can be calculated by multiplying the probability of the first event (A) by the probability of the second event (B) given that the first event has occurred (A).\n",
    "\n",
    "The joint probability can be extended to more than two events by applying the same principle. For example, the joint probability of three events A, B, and C would be:\n",
    "\n",
    "```\n",
    "P(A ∩ B ∩ C) = P(A) * P(B|A) * P(C|A ∩ B)\n",
    "\n",
    "In this case, the joint probability is calculated by multiplying the probabilities of each event given the occurrence of the previous events.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240a818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a062aca",
   "metadata": {},
   "source": [
    "Q4. What is chain rule of probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6caca1e",
   "metadata": {},
   "source": [
    "The chain rule of probability, also known as the multiplication rule, is a fundamental principle in probability theory that allows us to compute the probability of the joint occurrence of multiple events.\n",
    "\n",
    "The chain rule states that the joint probability of a set of events can be calculated by multiplying the conditional probabilities of each event given the occurrence of the previous events in the sequence.\n",
    "````\n",
    "Formally, for a sequence of events A₁, A₂, ..., Aₙ, the chain rule of probability is given by:\n",
    "\n",
    "P(A₁ ∩ A₂ ∩ ... ∩ Aₙ) = P(A₁) * P(A₂ | A₁) * P(A₃ | A₁ ∩ A₂) * ... * P(Aₙ | A₁ ∩ A₂ ∩ ... ∩ Aₙ₋₁)\n",
    "````\n",
    "In other words, the joint probability of the entire sequence is equal to the product of the probabilities of each event conditioned on the occurrence of all the previous events in the sequence.\n",
    "\n",
    "The chain rule is particularly useful when dealing with complex or dependent events, where the probability of an event may depend on the occurrence of one or more previous events. By breaking down the joint probability into conditional probabilities, the chain rule allows for the calculation of the overall probability by considering the individual probabilities of each event in a sequential manner.\n",
    "\n",
    "The chain rule can be applied iteratively to compute the joint probability of any number of events, provided the conditional probabilities for each event are known or can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf9034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b5d4586",
   "metadata": {},
   "source": [
    "Q5. What is conditional probability means? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec3d5a",
   "metadata": {},
   "source": [
    "Conditional probability is a concept in probability theory that quantifies the probability of an event occurring given that another event has already occurred. It represents the likelihood of an event happening under a specific condition.\n",
    "\n",
    "The conditional probability of event B given event A is denoted as P(B | A), which can be read as \"the probability of B given A.\"\n",
    "\n",
    "````\n",
    "The formula for conditional probability is derived from the definition of conditional probability:\n",
    "\n",
    "P(B | A) = P(A ∩ B) / P(A)\n",
    "\n",
    "where:\n",
    "P(A ∩ B) represents the joint probability of events A and B, i.e., the probability of both A and B occurring simultaneously, and\n",
    "P(A) represents the probability of event A.\n",
    "````\n",
    "\n",
    "The formula states that the conditional probability of event B given event A is equal to the joint probability of A and B divided by the probability of A. It measures the proportion of times event B is expected to occur among the times when event A has already occurred.\n",
    "\n",
    "The concept of conditional probability allows us to update probabilities based on new information or conditions. It enables us to refine our understanding of the likelihood of an event by considering the occurrence of another event as a given condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aee2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7889aa8",
   "metadata": {},
   "source": [
    "Q6. What are continuous random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064b870",
   "metadata": {},
   "source": [
    "In probability theory and statistics, continuous random variables are variables that can take any value within a specified range or interval, rather than being restricted to a finite set of possible values. They are usually associated with physical or natural phenomena that can be measured on a continuous scale, such as time, distance, or temperature.\n",
    "\n",
    "Unlike discrete random variables, which can only take on a countable set of values, continuous random variables have an infinite number of possible values, making them ideal for modeling real-world phenomena that are inherently continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca673599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a577d54",
   "metadata": {},
   "source": [
    "Q7. What are Bernoulli distributions? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b975f85",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (typically represented as 1) and failure (typically represented as 0). It is named after the Swiss mathematician Jacob Bernoulli.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter, often denoted as p, which represents the probability of success (or the probability of observing the value 1). The probability of failure (or the probability of observing the value 0) is given by 1 - p.\n",
    "\n",
    "````\n",
    "The probability mass function (PMF) of a Bernoulli distribution is defined as:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where:\n",
    "X is a random variable that takes on the value 1 or 0,\n",
    "x is the outcome of the random variable (either 1 or 0),\n",
    "p is the probability of success (or the probability of observing the value 1), and\n",
    "1 - p is the probability of failure (or the probability of observing the value 0).\n",
    "````\n",
    "\n",
    "The PMF equation calculates the probability of observing a specific outcome (x) given the parameter p. If x is 1, the PMF simplifies to p, representing the probability of success. If x is 0, the PMF simplifies to 1 - p, representing the probability of failure.\n",
    "\n",
    "The Bernoulli distribution is often used as a building block for more complex distributions and models. It is particularly useful for modeling binary outcomes or situations where only two possible outcomes exist, such as flipping a coin (heads or tails) or the success or failure of a single experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a014f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e74de9e4",
   "metadata": {},
   "source": [
    "Q8. What is binomial distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac698dbe",
   "metadata": {},
   "source": [
    "The binomial distribution is a discrete probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials, where each trial has two possible outcomes: success (typically represented as 1) or failure (typically represented as 0).\n",
    "\n",
    "The binomial distribution is characterized by two parameters: n and p. The parameter n represents the number of trials, and p represents the probability of success in each trial. The probability of failure in each trial is given by 1 - p.\n",
    "\n",
    "````\n",
    "The probability mass function (PMF) of a binomial distribution is given by the formula:\n",
    "\n",
    "P(X = k) = C(n, k) * p^k * (1 - p)^(n - k)\n",
    "or it can also be written as this\n",
    "P(r) = nCr · pr (1 − p)n−r\n",
    "\n",
    "where:\n",
    "X is a random variable that represents the number of successes,\n",
    "k is the number of successes we want to observe (0 ≤ k ≤ n),\n",
    "n is the number of trials,\n",
    "p is the probability of success in each trial,\n",
    "(1 - p) is the probability of failure in each trial, and\n",
    "C(n, k) is the binomial coefficient, which represents the number of ways to choose k successes from n trials and is calculated as C(n, k) = n! / (k! * (n - k)!)\n",
    "````\n",
    "\n",
    "The binomial distribution formula calculates the probability of observing k successes in n trials, given the parameters p and n. It combines the probability of k successes (p^k) with the probability of (n - k) failures ((1 - p)^(n - k)), multiplied by the binomial coefficient.\n",
    "\n",
    "The binomial distribution is commonly used to model scenarios with a fixed number of independent trials, such as the number of successful sales out of a fixed number of sales calls, the number of defective items in a sample, or the number of heads obtained when flipping a coin a fixed number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95bbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65ed40a",
   "metadata": {},
   "source": [
    "Q9. What is Poisson distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5ea87",
   "metadata": {},
   "source": [
    "The Poisson distribution is a discrete probability distribution that models the number of events occurring within a fixed interval of time or space when the events occur randomly and independently at a constant average rate. It is named after the French mathematician Siméon Denis Poisson.\n",
    "\n",
    "The Poisson distribution is characterized by a single parameter, often denoted as λ (lambda), which represents the average rate of events occurring per unit of time or space. The distribution describes the probability of observing a specific number of events within the interval.\n",
    "\n",
    "````\n",
    "The probability mass function (PMF) of a Poisson distribution is given by the formula:\n",
    "\n",
    "P(X = k) = (e^(-λ) * λ^k) / k!\n",
    "\n",
    "where:\n",
    "X is a random variable that represents the number of events,\n",
    "k is the number of events we want to observe (k = 0, 1, 2, ...),\n",
    "λ is the average rate of events per interval,\n",
    "e is the base of the natural logarithm (approximately 2.71828), and\n",
    "k! denotes the factorial of k.\n",
    "````\n",
    "\n",
    "The PMF equation calculates the probability of observing k events within the given interval, given the average rate λ. The term e^(-λ) * λ^k represents the likelihood of k events occurring, and dividing by k! accounts for the number of ways the k events can be arranged.\n",
    "\n",
    "The Poisson distribution is commonly used to model the occurrence of rare events, such as the number of phone calls received at a call center in a given time period, the number of accidents at an intersection in a day, or the number of emails received per hour. It is especially applicable when events occur independently and the average rate of occurrence remains constant across time or space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d18ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d36a4b",
   "metadata": {},
   "source": [
    "Q10. Define covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7d9eb",
   "metadata": {},
   "source": [
    "Covariance is a statistical measure that quantifies the relationship between two random variables. It measures how changes in one variable are associated with changes in another variable. More specifically, covariance measures the extent to which two variables vary together.\n",
    "\n",
    "The covariance between two random variables X and Y is denoted as Cov(X, Y). It can be computed using the following formula:\n",
    "\n",
    "````\n",
    "Cov(X, Y) = E[(X - E[X]) * (Y - E[Y])]\n",
    "\n",
    "where:\n",
    "E[X] represents the expected value (mean) of variable X,\n",
    "E[Y] represents the expected value (mean) of variable Y,\n",
    "(X - E[X]) is the deviation of X from its mean,\n",
    "(Y - E[Y]) is the deviation of Y from its mean, and\n",
    "E[.] denotes the expected value or average.\n",
    "````\n",
    "\n",
    "Intuitively, the covariance is positive when X and Y tend to increase or decrease together (positive association), negative when one tends to increase while the other decreases (negative association), and close to zero when there is no clear linear relationship between the variables (no association).\n",
    "\n",
    "The magnitude of the covariance does not provide a standardized measure of the strength of the relationship. To obtain a standardized measure, the covariance is often divided by the product of the standard deviations of the variables, resulting in the correlation coefficient.\n",
    "\n",
    "It's important to note that covariance only measures the linear relationship between variables. It does not indicate the strength or causality of the relationship, and it can be influenced by the scale of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d64988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8c26d83",
   "metadata": {},
   "source": [
    "Q11. Define correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38683d9",
   "metadata": {},
   "source": [
    "Correlation is a statistical measure that describes the relationship between two variables. It quantifies the degree to which changes in one variable are associated with changes in another variable. Correlation assesses both the direction and strength of the relationship between variables.\n",
    "\n",
    "The correlation coefficient, typically denoted as r, is used to measure correlation. It ranges between -1 and 1, where:\n",
    "\n",
    "- A correlation coefficient of 1 indicates a perfect positive correlation, meaning that as one variable increases, the other variable increases proportionally.\n",
    "- A correlation coefficient of -1 indicates a perfect negative correlation, meaning that as one variable increases, the other variable decreases proportionally.\n",
    "- A correlation coefficient of 0 indicates no linear correlation, meaning that there is no clear relationship between the variables.\n",
    "\n",
    "The correlation coefficient is computed using the following formula:\n",
    "\n",
    "````\n",
    "r = (Σ((X - μX) * (Y - μY))) / (n * σX * σY)\n",
    "\n",
    "where:\n",
    "- X and Y are the values of the two variables\n",
    "- μX and μY are the means (averages) of X and Y, respectively\n",
    "- σX and σY are the standard deviations of X and Y, respectively\n",
    "- Σ represents the sum of the products of the deviations of X and Y from their respective means\n",
    "- n is the number of data points (observations)\n",
    "````\n",
    "\n",
    "The correlation coefficient provides a standardized measure of the linear relationship between variables, regardless of the scale or units of measurement. It allows us to assess the strength and direction of the relationship, with values closer to -1 or 1 indicating a stronger correlation, and values closer to 0 indicating a weaker or no correlation.\n",
    "\n",
    "It's important to note that correlation does not imply causation. It only measures the strength and direction of the relationship between variables, without determining the cause-and-effect relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b190494f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "652dab65",
   "metadata": {},
   "source": [
    "Q12. Define sampling with replacement. Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af628edc",
   "metadata": {},
   "source": [
    "Sampling with replacement is a method of selecting data points from a population or sample, where each selected data point is returned to the population or sample before the next selection is made. This means that each data point has an equal chance of being selected again in subsequent draws.\n",
    "\n",
    "In sampling with replacement, the selected data point is not removed or excluded from the population or sample after it is selected. This allows for the possibility of selecting the same data point multiple times in the sampling process.\n",
    "\n",
    "An example of sampling with replacement is the process of drawing balls from an urn. Imagine an urn filled with colored balls, such as red, blue, and green balls. Each time a ball is drawn from the urn, its color is recorded, and then the ball is placed back into the urn. The process is repeated, and a new ball is drawn each time.\n",
    "\n",
    "With sampling with replacement, after drawing a ball, it is returned to the urn before the next draw. This means that each time a ball is drawn, there is an equal probability of drawing any of the available colors, regardless of the previous draws.\n",
    "\n",
    "Sampling with replacement is commonly used in statistical analysis and simulations, where the assumption of independence and equal probabilities for each draw is desired. It allows for the creation of random samples that resemble the original population or sample, and it simplifies calculations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd732b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22079a51",
   "metadata": {},
   "source": [
    "Q13. What is sampling without replacement? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a84507",
   "metadata": {},
   "source": [
    "Sampling without replacement is a method of selecting data points from a population or sample in which each selected data point is not returned to the population or sample before the next selection is made. This means that once a data point is selected, it is removed or excluded from further consideration in the sampling process.\n",
    "\n",
    "In sampling without replacement, the selected data point is not put back into the population or sample, which reduces the pool of available data points for subsequent selections.\n",
    "\n",
    "An example of sampling without replacement is the process of drawing cards from a deck. Suppose you have a standard deck of 52 playing cards, and you want to draw a sequence of cards from the deck. In the first draw, you randomly select one card from the deck. Without replacing the card back into the deck, you then draw another card from the remaining deck. This process continues until you have drawn the desired number of cards.\n",
    "\n",
    "With sampling without replacement, as you draw cards from the deck, the number of remaining cards decreases, affecting the probabilities of subsequent draws. Each subsequent draw has a slightly different probability distribution due to the reduced pool of available cards.\n",
    "\n",
    "Sampling without replacement is commonly used in situations where it is important to ensure that each data point is included only once in the sample. It is often used in survey sampling, quality control, and various statistical analyses where the assumption of independence among selected data points is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff324e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88c9b6f5",
   "metadata": {},
   "source": [
    "Q14. What is hypothesis? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab10f50",
   "metadata": {},
   "source": [
    "In statistics, a hypothesis is a statement or assumption about a population or a phenomenon that is subject to testing and evaluation based on available data. It is a proposed explanation or claim that is formulated before conducting a study or analysis.\n",
    "\n",
    "There are two types of hypotheses commonly used in statistical hypothesis testing:\n",
    "\n",
    "1. Null Hypothesis (H₀): The null hypothesis represents the default or initial assumption that there is no significant relationship, effect, or difference between variables or groups being studied. It assumes that any observed differences or effects are due to random chance or sampling variability. The null hypothesis is denoted as H₀.\n",
    "\n",
    "2. Alternative Hypothesis (H₁ or Ha): The alternative hypothesis contradicts or opposes the null hypothesis. It proposes that there is a specific relationship, effect, or difference between variables or groups being studied, beyond what would be expected by chance alone. The alternative hypothesis is denoted as H₁ or Ha.\n",
    "\n",
    "````\n",
    "Example:\n",
    "Suppose a researcher wants to investigate whether a new drug is effective in reducing blood pressure. They might formulate the following null and alternative hypotheses:\n",
    "\n",
    "Null Hypothesis (H₀): The new drug has no effect on reducing blood pressure.\n",
    "Alternative Hypothesis (H₁): The new drug significantly reduces blood pressure.\n",
    "````\n",
    "The researcher would then collect data through a controlled experiment or study and analyze the results to determine whether there is sufficient evidence to reject the null hypothesis in favor of the alternative hypothesis. Hypothesis testing involves comparing the observed data with what would be expected if the null hypothesis were true, using statistical tests and measures to assess the level of evidence against the null hypothesis.\n",
    "\n",
    "The purpose of hypothesis testing is to make inferences and draw conclusions about the population based on the available sample data, while considering the possibility of errors in decision-making (Type I and Type II errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
